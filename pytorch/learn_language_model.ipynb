{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# http://www.nltk.org/howto/wordnet.html\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'id', 'type', 'rating', 'pol', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Location of test/train data files on local computer, data downloaded directly from Stanford source[2]\n",
    "#test_dir = '/Users/philiposborne/Documents/Written Notes/Learning Notes/IMDB Reviews/IMDB Data/test'\n",
    "#train_dir = '/Users/philiposborne/Documents/Written Notes/Learning Notes/IMDB Reviews/IMDB Data/train'\n",
    "\n",
    "data = pd.read_csv(\"/Users/wofeishenling/python_note/Python_Road/pytorch/imdb_master.csv\")\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'id', 'type', 'rating', 'pol', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Select only training data\n",
    "data = data[data['type']=='train'].reset_index(drop=True)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments in data: 25000\n",
      "Number of comments left in data after removal: 1000\n"
     ]
    }
   ],
   "source": [
    "print('Number of comments in data:', len(data))\n",
    "\n",
    "data = data[0:1000]\n",
    "\n",
    "print('Number of comments left in data after removal:', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef IMDB_to_csv(directory):    \\n    data = pd.DataFrame()\\n    \\n    for filename in glob.glob(str(directory)+\\'/neg/*.txt\\'):\\n        with open(filename, \\'r\\',  encoding=\"utf8\") as f:\\n            content = f.readlines()\\n            content_table = pd.DataFrame({\\'id\\':filename.split(\\'_\\')[0].split(\\'/\\')[-1],\\'rating\\':filename.split(\\'_\\')[1].split(\\'.\\')[0],\\'pol\\':\\'neg\\', \\'text\\':content})\\n        data = data.append(content_table)\\n        \\n    for filename in glob.glob(str(directory)+\\'/pos/*.txt\\'):\\n        with open(filename, \\'r\\',  encoding=\"utf8\") as f:\\n            content = f.readlines()\\n            content_table = pd.DataFrame({\\'id\\':filename.split(\\'_\\')[0].split(\\'/\\')[-1],\\'rating\\':filename.split(\\'_\\')[1].split(\\'.\\')[0],\\'pol\\':\\'pos\\', \\'text\\':content})\\n        data = data.append(content_table)\\n    data = data.sort_values([\\'pol\\',\\'id\\'])\\n    data = data.reset_index(drop=True)\\n    #data[\\'rating_norm\\'] = (data[\\'rating\\'] - data[\\'rating\\'].min())/( data[\\'rating\\'].max() - data[\\'rating\\'].min() )\\n\\n    return(data)\\n\\ntrain_data = IMDB_to_csv(train_dir)\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data import written as a function:\n",
    "# Replace test and train dir with correct path for file saved on local computer\n",
    "# Data files are downloaded from reference link above where main file name is changed to IMDB Data\n",
    "\n",
    "# This function converts the raw files form the original Stanford source into csv files.\n",
    "\"\"\"\n",
    "def IMDB_to_csv(directory):    \n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    for filename in glob.glob(str(directory)+'/neg/*.txt'):\n",
    "        with open(filename, 'r',  encoding=\"utf8\") as f:\n",
    "            content = f.readlines()\n",
    "            content_table = pd.DataFrame({'id':filename.split('_')[0].split('/')[-1],'rating':filename.split('_')[1].split('.')[0],'pol':'neg', 'text':content})\n",
    "        data = data.append(content_table)\n",
    "        \n",
    "    for filename in glob.glob(str(directory)+'/pos/*.txt'):\n",
    "        with open(filename, 'r',  encoding=\"utf8\") as f:\n",
    "            content = f.readlines()\n",
    "            content_table = pd.DataFrame({'id':filename.split('_')[0].split('/')[-1],'rating':filename.split('_')[1].split('.')[0],'pol':'pos', 'text':content})\n",
    "        data = data.append(content_table)\n",
    "    data = data.sort_values(['pol','id'])\n",
    "    data = data.reset_index(drop=True)\n",
    "    #data['rating_norm'] = (data['rating'] - data['rating'].min())/( data['rating'].max() - data['rating'].min() )\n",
    "\n",
    "    return(data)\n",
    "\n",
    "train_data = IMDB_to_csv(train_dir)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'id', 'type', 'rating', 'pol', 'text'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id-</th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>rating</th>\n",
       "      <th>pol</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>Robert DeNiro plays the most unbelievably inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "      <td>This film had a lot of promise, and the plot w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>OK its not the best film I've ever seen but at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>The plot for Descent, if it actually can be ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id-    id dataset  rating  pol  \\\n",
       "0    0     0   train       3  neg   \n",
       "1    1     1   train       1  neg   \n",
       "2    2    10   train       2  neg   \n",
       "3    3   100   train       3  neg   \n",
       "4    4  1000   train       4  neg   \n",
       "\n",
       "                                                text  \n",
       "0  Story of a man who has unnatural feelings for ...  \n",
       "1  Robert DeNiro plays the most unbelievably inte...  \n",
       "2  This film had a lot of promise, and the plot w...  \n",
       "3  OK its not the best film I've ever seen but at...  \n",
       "4  The plot for Descent, if it actually can be ca...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.columns)\n",
    "train_data.columns = ['id-', 'id', 'dataset', 'rating', 'pol', 'text']\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Story of a man who has unnatural feelings for a pig',\n",
       " ' Starts out with a opening scene that is a terrific example of absurd comedy',\n",
       " \" A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers\",\n",
       " ' Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting',\n",
       " ' Even those from the era should be turned off',\n",
       " ' The cryptic dialogue would make Shakespeare seem easy to a third grader',\n",
       " \" On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond\",\n",
       " ' Future stars Sally Kirkland and Frederic Forrest can be seen briefly',\n",
       " '']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][0].split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Story of a man who has unnatural feelings for a pig'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][0].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['text'][0].split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][0].split('.')[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of comments completed: 99.9 %\n",
      "Total run time =  0.6098333333333333  minutes\n"
     ]
    }
   ],
   "source": [
    "train_data_sent = pd.DataFrame()\n",
    "\n",
    "start_time = time.time()\n",
    "for index in train_data.index:\n",
    "    data_row = train_data.iloc[index,:]\n",
    "\n",
    "    for sent_id in range(0,len(data_row['text'].split('.'))-1):\n",
    "        sentence = data_row['text'].split('.')[sent_id]\n",
    "        # Form a row in a dataframe for this setence that captures the words and keeps ids and polarity scores\n",
    "        # We must pass an arbitrary index which we then reset to show unique numbers\n",
    "        sentence_row = pd.DataFrame({\n",
    "                                     'id':data_row['id'],\n",
    "                                     'pol':data_row['pol'],\n",
    "                                     'sent_id':sent_id,\n",
    "                                     'sentence':sentence}, index = [index]) \n",
    "        \n",
    "        # Form full table that has rows for all sentences\n",
    "        train_data_sent = train_data_sent.append(sentence_row)\n",
    "    \n",
    "    \n",
    "    # Outputs progress of main loop, see:\n",
    "    clear_output(wait=True)\n",
    "    print('Proportion of comments completed:', np.round(index/len(train_data),4)*100,'%')\n",
    "    \n",
    "end_time = time.time()\n",
    "print('Total run time = ', np.round(end_time-start_time,2)/60, ' minutes')\n",
    "# Reset index so that each index value is a unique number\n",
    "train_data_sent = train_data_sent.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pol</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>Starts out with a opening scene that is a ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>2</td>\n",
       "      <td>A formal orchestra audience is turned into an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>3</td>\n",
       "      <td>Unfortunately it stays absurd the WHOLE time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>4</td>\n",
       "      <td>Even those from the era should be turned off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  pol  sent_id                                           sentence\n",
       "0   0  neg        0  Story of a man who has unnatural feelings for ...\n",
       "1   0  neg        1   Starts out with a opening scene that is a ter...\n",
       "2   0  neg        2   A formal orchestra audience is turned into an...\n",
       "3   0  neg        3   Unfortunately it stays absurd the WHOLE time ...\n",
       "4   0  neg        4       Even those from the era should be turned off"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pol</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>&lt;s story of a man who has unnatural feelings f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>Starts out with a opening scene that is a ter...</td>\n",
       "      <td>&lt;s  starts out with a opening scene that is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>2</td>\n",
       "      <td>A formal orchestra audience is turned into an...</td>\n",
       "      <td>&lt;s  a formal orchestra audience is turned into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>3</td>\n",
       "      <td>Unfortunately it stays absurd the WHOLE time ...</td>\n",
       "      <td>&lt;s  unfortunately it stays absurd the whole ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>4</td>\n",
       "      <td>Even those from the era should be turned off</td>\n",
       "      <td>&lt;s  even those from the era should be turned o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  pol  sent_id                                           sentence  \\\n",
       "0   0  neg        0  Story of a man who has unnatural feelings for ...   \n",
       "1   0  neg        1   Starts out with a opening scene that is a ter...   \n",
       "2   0  neg        2   A formal orchestra audience is turned into an...   \n",
       "3   0  neg        3   Unfortunately it stays absurd the WHOLE time ...   \n",
       "4   0  neg        4       Even those from the era should be turned off   \n",
       "\n",
       "                                      sentence_clean  \n",
       "0  <s story of a man who has unnatural feelings f...  \n",
       "1  <s  starts out with a opening scene that is a ...  \n",
       "2  <s  a formal orchestra audience is turned into...  \n",
       "3  <s  unfortunately it stays absurd the whole ti...  \n",
       "4  <s  even those from the era should be turned o...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sent['sentence_clean'] = train_data_sent['sentence'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "train_data_sent['sentence_clean'] = train_data_sent['sentence_clean'].str.lower()\n",
    "\n",
    "train_data_sent['sentence_clean'] = '<s ' + train_data_sent['sentence_clean']\n",
    "train_data_sent['sentence_clean'] = train_data_sent['sentence_clean'] + ' /s>'\n",
    "\n",
    "train_data_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s story of a man who has unnatural feelings for a pig /s> <s  starts out with a opening scene that '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train_data_sent['sentence_clean']\n",
    "text_list = \" \".join(map(str, text))\n",
    "text_list[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = pd.DataFrame({'words':text.str.split(' ', expand = True).stack().unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of words completed: 99.99 %\n"
     ]
    }
   ],
   "source": [
    "word_count_table = pd.DataFrame()\n",
    "for n,word in enumerate(word_list['words']):\n",
    "    # Create a list of just the word we are interested in, we use regular expressions so that part of words do not count\n",
    "    # e.g. 'ear' would be counted in each appearance of the word 'year'\n",
    "    word_count = len(re.findall(' ' + word + ' ', text_list))  \n",
    "    word_count_table = word_count_table.append(pd.DataFrame({'count':word_count}, index=[n]))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Proportion of words completed:', np.round(n/len(word_list),4)*100,'%')\n",
    "\n",
    "word_list['count'] = word_count_table['count']\n",
    "# Remove the count for the start and end of sentence notation so \n",
    "# that these do not inflate the other probabilities\n",
    "word_list['count'] = np.where(word_list['words'] == '<s' , 0,\n",
    "                     np.where(word_list['words'] == '/s>', 0,\n",
    "                     word_list['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>prob</th>\n",
       "      <th>w-len</th>\n",
       "      <th>rank</th>\n",
       "      <th>mul_count_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>the</td>\n",
       "      <td>12297</td>\n",
       "      <td>0.054378</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>11032</td>\n",
       "      <td>0.048784</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>5911</td>\n",
       "      <td>0.026139</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>and</td>\n",
       "      <td>5350</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>5156</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>to</td>\n",
       "      <td>5152</td>\n",
       "      <td>0.022782</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30912.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>is</td>\n",
       "      <td>3738</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>in</td>\n",
       "      <td>3223</td>\n",
       "      <td>0.014252</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25784.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>i</td>\n",
       "      <td>3219</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>this</td>\n",
       "      <td>3043</td>\n",
       "      <td>0.013456</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>it</td>\n",
       "      <td>2914</td>\n",
       "      <td>0.012886</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>that</td>\n",
       "      <td>2737</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>was</td>\n",
       "      <td>1963</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>movie</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>br</td>\n",
       "      <td>1915</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>but</td>\n",
       "      <td>1606</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>for</td>\n",
       "      <td>1581</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>with</td>\n",
       "      <td>1527</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>as</td>\n",
       "      <td>1504</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>not</td>\n",
       "      <td>1256</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     words  count      prob  w-len  rank  mul_count_rank\n",
       "34     the  12297  0.054378      3   1.0         12297.0\n",
       "12          11032  0.048784      0   2.0         22064.0\n",
       "3        a   5911  0.026139      1   3.0         17733.0\n",
       "87     and   5350  0.023658      3   4.0         21400.0\n",
       "2       of   5156  0.022800      2   5.0         25780.0\n",
       "66      to   5152  0.022782      2   6.0         30912.0\n",
       "19      is   3738  0.016530      2   7.0         26166.0\n",
       "124     in   3223  0.014252      2   8.0         25784.0\n",
       "177      i   3219  0.014235      1   9.0         28971.0\n",
       "101   this   3043  0.013456      4  10.0         30430.0\n",
       "40      it   2914  0.012886      2  11.0         32054.0\n",
       "18    that   2737  0.012103      4  12.0         32844.0\n",
       "168    was   1963  0.008680      3  13.0         25519.0\n",
       "102  movie   1954  0.008641      5  14.0         27356.0\n",
       "141     br   1915  0.008468      2  15.0         28725.0\n",
       "139    but   1606  0.007102      3  16.0         25696.0\n",
       "9      for   1581  0.006991      3  17.0         26877.0\n",
       "15    with   1527  0.006752      4  18.0         27486.0\n",
       "212     as   1504  0.006651      2  19.0         28576.0\n",
       "116    not   1256  0.005554      3  20.0         25120.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list['prob'] = word_list['count']/sum(word_list['count'])\n",
    "word_list = word_list.sort_values(ascending=False ,by='prob')\n",
    "word_list['w-len'] = word_list['words'].str.len()\n",
    "word_list['rank'] = word_list['count'].rank(method='first',ascending=False)\n",
    "word_list['mul_count_rank'] = word_list['count']*word_list['rank']\n",
    "\n",
    "word_list.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='count', ylabel='mul_count_rank'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_list.head(10)\n",
    "word_list.plot.scatter(x=\"count\", y=\"mul_count_rank\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading gutenberg: <urlopen error [Errno 54]\n",
      "[nltk_data]     Connection reset by peer>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据\n",
    "x_num=np.array(np.arange(15))\n",
    "y_num=10*x_num+20*np.random.random(15)\n",
    "fig = plt.figure()\n",
    "# 画图（点图）\n",
    "# fig, ax = plt.subplots()\n",
    " \n",
    "ax = fig.add_subplot(3,2,1)\n",
    "ax.scatter(x_num, y_num)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel(' y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_table = pd.DataFrame()\n",
    "\n",
    "start_time = time.time()\n",
    "# Loop through each sentence\n",
    "# REMOVE ROW LIMIT FOR FULL RUN\n",
    "for index in train_data_sent[0:200].index:#get top 200\n",
    "    data_row = train_data_sent.iloc[index,:]\n",
    "\n",
    "    sent_probs = pd.DataFrame()\n",
    "    # Go through each word in the sentence, lookup the probability of the word and \n",
    "    # then find the mulitplicitive product of all probabilities in the sentence.\n",
    "    for n,word in enumerate(data_row['sentence_clean'].split(' ')):\n",
    "        sent_probs = sent_probs.append(pd.DataFrame({'prob':word_list[ word_list['words']==word]['prob']}, index = [n]))\n",
    "    unigram = sent_probs['prob'].prod(axis=0)\n",
    "    \n",
    "    # Create a list of unigram calculation for each sentence\n",
    "    unigram_table = unigram_table.append(pd.DataFrame({'unigram':unigram},index = [index]))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Proportion of sentences completed:', np.round(index/len(train_data_sent),4)*100,'%')\n",
    "        \n",
    "end_time = time.time()\n",
    "print('Total run time = ', np.round(end_time-start_time,2)/60, ' minutes')\n",
    "\n",
    "train_data_sent['unigram'] = unigram_table['unigram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_table.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_table_log = pd.DataFrame()\n",
    "\n",
    "start_time_log = time.time()\n",
    "# Loop through each sentence\n",
    "# REMOVE ROW LIMIT FOR FULL RUN\n",
    "for index in train_data_sent[0:200].index:\n",
    "    data_row = train_data_sent.iloc[index,:]\n",
    "\n",
    "    sent_probs = pd.DataFrame()\n",
    "    # Go through each word in the sentence, lookup the probability of the word and \n",
    "    # then find the mulitplicitive product of all probabilities in the sentence.\n",
    "    for n,word in enumerate(data_row['sentence_clean']):\n",
    "        log_prob = np.log10(word_list[ word_list['words']==word]['prob'])\n",
    "        sent_probs = sent_probs.append(pd.DataFrame({'log_prob':log_prob}, index = [n]))\n",
    "        \n",
    "    unigram_log = sum(sent_probs['log_prob'])\n",
    "    \n",
    "    # Create a list of unigram calculation for each sentence\n",
    "    unigram_table_log = unigram_table.append(pd.DataFrame({'unigram_log':unigram_log},index = [index]))\n",
    "                                         \n",
    "    clear_output(wait=True)\n",
    "    print('Proportion of sentences completed:', np.round(index/len(train_data_sent),4)*100,'%')\n",
    "                                                                   \n",
    "end_time_log = time.time()\n",
    "print('Total run time = ', np.round(end_time_log-start_time_log,2)/60, ' minutes')\n",
    "\n",
    "#train_data_sent['unigram_log'] = unigram_table_log['unigram_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_1 = 'to'\n",
    "word_2 = 'a'\n",
    "\n",
    "prob_word_1 = word_list[word_list['words'] == word_1]['prob'].iloc[0]\n",
    "prob_word_2 = word_list[word_list['words'] == word_2]['prob'].iloc[0]\n",
    "\n",
    "unigram_prob = prob_word_1*prob_word_2\n",
    "\n",
    "print('The unigram probability of the word \"a\" occuring given the word \"to\" was the previous word is: ', np.round(unigram_prob,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_1 = ' ' + str('to') + ' '\n",
    "word_2 = str('a') + ' '\n",
    "\n",
    "bigram_prob = len(re.findall(word_1 + word_2, text_list)) / len(re.findall(word_1, text_list)) \n",
    "\n",
    "print('The probability of the word \"a\" occuring given the word \"to\" was the previous word is: ', np.round(bigram_prob,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_W_Matrix = pd.DataFrame({'words': word_list['words']})\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Add limits to number of columns/rows so this doesn't run for ages\n",
    "column_lim = 1000\n",
    "#column_lim = len(W_W_Matrix)\n",
    "row_lim = 10\n",
    "#row_lim = len(W_W_Matrix)\n",
    "\n",
    "for r, column in enumerate(W_W_Matrix['words'][0:column_lim]):\n",
    "    \n",
    "    prob_table = pd.DataFrame()\n",
    "    for i, row in enumerate(W_W_Matrix['words'][0:row_lim]):\n",
    "\n",
    "        word_1 = ' ' + str(row) + ' '\n",
    "        word_2 = str(column) + ' '\n",
    "\n",
    "        if len(re.findall(word_1, text_list)) == 0:\n",
    "            prob = pd.DataFrame({'prob':[0]}, index=[i])\n",
    "        else:\n",
    "            prob = pd.DataFrame({'prob':[len(re.findall(word_1 + word_2, text_list)) / len(re.findall(word_1, text_list)) ]}, index=[i])\n",
    "        \n",
    "        prob_table = prob_table.append(prob)\n",
    "    W_W_Matrix[str(column)] = prob_table['prob']\n",
    "    \n",
    "    # Outputs progress of main loop, see:\n",
    "    clear_output(wait=True)\n",
    "    print('Proportion of column words completed:', np.round(r/len(W_W_Matrix[0:column_lim]),2)*100,'%')\n",
    "    \n",
    "end_time = time.time()\n",
    "print('Total run time = ', np.round(end_time-start_time,2)/60, ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_W_Matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,row_lim):\n",
    "    plt.bar(W_W_Matrix.iloc[i,1:].sort_values(ascending=False)[1:10].index,W_W_Matrix.iloc[i,1:].sort_values(ascending=False)[1:10].values)\n",
    "    plt.title('Most Common Words that Follow the word: ' +str(W_W_Matrix.iloc[i,0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.linspace(0,1,50)\n",
    "H = [-(p*np.log2(p) + (1-p)*np.log(1-p)) for p in p]\n",
    "# Replace nan output with 0 \n",
    "H = [0 if math.isnan(x) else x for x in H]\n",
    "\n",
    "plt.plot(p,H)\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1])\n",
    "plt.xlabel('Probability of Heads (p)')\n",
    "plt.ylabel('Entropy (H(p))')\n",
    "plt.title('The Entropy of a Bias Coin as \\n the Probabilitiy of Heads Varies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_1 = text.iloc[0]\n",
    "sent_2 = text.iloc[1]\n",
    "\n",
    "print('Sentence 1', sent_1)\n",
    "print('--.--.--.--.--.--.--.--')\n",
    "print('Sentence 2', sent_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prob = word_list[['words','count','prob']]\n",
    "data_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(sentence, data_prob):\n",
    "    entropy_table = pd.DataFrame()\n",
    "    for n,word in enumerate(sentence.split(' ')):\n",
    "        # log2(0) provide nan so return 0 instead\n",
    "        if ((data_prob[data_prob['words']==word]['prob'].iloc[0]) == 0):\n",
    "            entropy = 0\n",
    "        else:\n",
    "            prob = data_prob[data_prob['words']==word]['prob'].iloc[0]\n",
    "            entropy = prob*np.log2(prob)\n",
    "        entropy_table = entropy_table.append(pd.DataFrame({'word':word,\n",
    "                                                            'entropy':entropy}, index = [n]))\n",
    "    phrase_entropy = -1*sum(entropy_table['entropy'])\n",
    "    return(phrase_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_1_entropy = entropy(sent_1,data_prob)\n",
    "sent_2_entropy = entropy(sent_2,data_prob)\n",
    "\n",
    "print('Sentence 1: ', sent_1)\n",
    "print('Sentence 1 entropy: ', np.round(sent_1_entropy,5))\n",
    "print('Per-word Sentence 1 entropy: ', np.round(sent_1_entropy/len(sent_1.split(' ')),5))\n",
    "\n",
    "print('--.--.--.--.--.--.--.--')\n",
    "print('Sentence 2: ', sent_2)\n",
    "print('Sentence 2 entropy: ', np.round(sent_2_entropy,5))\n",
    "print('Per-word Sentence 2 entropy: ', np.round(sent_2_entropy/len(sent_2.split(' ')),5))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f87c41940a98a1a06bde016bc11ff418ea3d5a21d6fa78193519d8f174f35359"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('stopwords': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
